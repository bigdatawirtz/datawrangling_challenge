{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "70b1df15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae250df5",
   "metadata": {},
   "source": [
    "Configuracion Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b794b2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset original cargado. Filas iniciales: 100000\n",
      "Iniciando la introducción de 11 tipos de errores...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "file_path = 'Amazon.csv'\n",
    "if not os.path.exists(file_path):\n",
    "    print(f\"ERROR: Archivo no encontrado en {file_path}. Asegúrate de subirlo.\")\n",
    "    exit()\n",
    "\n",
    "# Cargar y hacer una copia para ensuciar\n",
    "df = pd.read_csv(file_path)\n",
    "df_dirty = df.copy()\n",
    "\n",
    "print(f\"Dataset original cargado. Filas iniciales: {len(df)}\")\n",
    "print(\"Iniciando la introducción de 11 tipos de errores...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a98baa02",
   "metadata": {},
   "source": [
    "Introducción de Datos Faltantes (NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7b91004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores de Datos Faltantes (NaN) introducidos en UnitPrice, Discount y City.\n"
     ]
    }
   ],
   "source": [
    "# UnitPrice: 5% NaN\n",
    "mask_unitprice = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.05, 0.95])\n",
    "df_dirty.loc[mask_unitprice, 'UnitPrice'] = np.nan\n",
    "\n",
    "# Discount: 3% NaN\n",
    "mask_discount = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.03, 0.97])\n",
    "df_dirty.loc[mask_discount, 'Discount'] = np.nan\n",
    "\n",
    "# City: 1% NaN\n",
    "mask_city = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.01, 0.99])\n",
    "df_dirty.loc[mask_city, 'City'] = np.nan\n",
    "print(\"Errores de Datos Faltantes (NaN) introducidos en UnitPrice, Discount y City.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b803af",
   "metadata": {},
   "source": [
    "Introducción de Filas Duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "b5d1dfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 filas duplicadas exactas añadidas. Total de filas: 100050\n"
     ]
    }
   ],
   "source": [
    "# Añadir 50 duplicados exactos de las primeras 50 filas\n",
    "duplicates = df_dirty.iloc[:50].copy()\n",
    "df_dirty = pd.concat([df_dirty, duplicates], ignore_index=True)\n",
    "print(f\"50 filas duplicadas exactas añadidas. Total de filas: {len(df_dirty)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf1db19",
   "metadata": {},
   "source": [
    "Introducción de Valores Atípicos (Outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "538a8f1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores atípicos extremos introducidos en Quantity (100 filas).\n"
     ]
    }
   ],
   "source": [
    "# Insertar valores extremos en 'Quantity' (0.1% de las filas originales)\n",
    "outlier_count = int(df.shape[0] * 0.001)\n",
    "outlier_indices = np.random.choice(df_dirty.index, size=outlier_count, replace=False)\n",
    "df_dirty.loc[outlier_indices, 'Quantity'] = np.random.choice([999, 1000, 10000], size=outlier_count)\n",
    "print(f\"Valores atípicos extremos introducidos en Quantity ({outlier_count} filas).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c836a7c",
   "metadata": {},
   "source": [
    "Inconsistencias de Formato (Fecha y Símbolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b1503c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inconsistencias de formato de fecha (MM/DD/YYYY) introducidas.\n",
      "Símbolo '€' y conversión a string introducidos en TotalAmount.\n"
     ]
    }
   ],
   "source": [
    "# OrderDate: Cambiar 10% a 'MM/DD/YYYY'\n",
    "date_format_mask = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.10, 0.90])\n",
    "dates_to_change = pd.to_datetime(df_dirty.loc[date_format_mask, 'OrderDate'], errors='coerce')\n",
    "df_dirty.loc[date_format_mask, 'OrderDate'] = dates_to_change.dt.strftime('%m/%d/%Y')\n",
    "print(\"Inconsistencias de formato de fecha (MM/DD/YYYY) introducidas.\")\n",
    "\n",
    "# TotalAmount: Añadir '€' y convertir a string (Símbolo Extra)\n",
    "total_amount_mask = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.02, 0.98])\n",
    "\n",
    "# CORRECCIÓN para evitar FutureWarning: Convertir toda la columna a 'object'\n",
    "df_dirty['TotalAmount'] = df_dirty['TotalAmount'].astype(object) \n",
    "\n",
    "# Ahora introducir el error (string + símbolo) en el 2% de los valores\n",
    "df_dirty.loc[total_amount_mask, 'TotalAmount'] = df_dirty.loc[total_amount_mask, 'TotalAmount'].astype(str) + '€'\n",
    "print(\"Símbolo '€' y conversión a string introducidos en TotalAmount.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18db67cb",
   "metadata": {},
   "source": [
    "Errores Tipográficos y Categorías Extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f151ca06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errores tipográficos introducidos en la columna Category.\n",
      "Categoría 'UNKNOWN' introducida en PaymentMethod.\n"
     ]
    }
   ],
   "source": [
    "# Category (Error 8: Errores de Deletreo)\n",
    "replacement_map = {'Books': 'Boks', 'Clothing': 'Clothng', 'Electronics': 'Electrincs'}\n",
    "category_mask = df_dirty['Category'].isin(replacement_map.keys())\n",
    "category_corrupt_indices = df_dirty[category_mask].sample(frac=0.1, random_state=42).index\n",
    "\n",
    "for original, corrupted in replacement_map.items():\n",
    "    df_dirty.loc[category_corrupt_indices, 'Category'] = df_dirty.loc[category_corrupt_indices, 'Category'].replace(original, corrupted)\n",
    "print(\"Errores tipográficos introducidos en la columna Category.\")\n",
    "\n",
    "# PaymentMethod (Error 9: Categoría 'UNKNOWN')\n",
    "payment_mask = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.01, 0.99])\n",
    "df_dirty.loc[payment_mask, 'PaymentMethod'] = 'UNKNOWN'\n",
    "print(\"Categoría 'UNKNOWN' introducida en PaymentMethod.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a108e9",
   "metadata": {},
   "source": [
    "Tipo de Dato Incorrecto y Encabezado Incorrecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "58a172c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tipo de dato incorrecto (string) introducido en ShippingCost (ahora es tipo 'object').\n"
     ]
    }
   ],
   "source": [
    "# ShippingCost\n",
    "shipping_cost_mask = np.random.choice([True, False], size=df_dirty.shape[0], p=[0.05, 0.95])\n",
    "\n",
    "# Convertir toda la columna a 'object' (string/mixto) para evitar la FutureWarning\n",
    "df_dirty['ShippingCost'] = df_dirty['ShippingCost'].astype(object)\n",
    "\n",
    "# Ahora introduce el string en el 5% de los valores sin generar el Warning\n",
    "df_dirty.loc[shipping_cost_mask, 'ShippingCost'] = \\\n",
    "    df_dirty.loc[shipping_cost_mask, 'ShippingCost'].apply(lambda x: str(x))\n",
    "\n",
    "print(\"Tipo de dato incorrecto (string) introducido en ShippingCost (ahora es tipo 'object').\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9ac5a8",
   "metadata": {},
   "source": [
    "Guardar y Verificación Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2454b44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- RESUMEN DEL DATASET SUCIO ---\n",
      "¡Conjunto de datos sucio guardado como: Amazon_DIRTY.csv!\n",
      "\n",
      "Información de Tipos de Datos (Dtypes):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100050 entries, 0 to 100049\n",
      "Data columns (total 20 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0   OrderID        100050 non-null  object \n",
      " 1   OrderDate      100050 non-null  object \n",
      " 2   CustomerID     100050 non-null  object \n",
      " 3   CustomerName   100050 non-null  object \n",
      " 4   ProductID      100050 non-null  object \n",
      " 5   ProductName    100050 non-null  object \n",
      " 6   Category       100050 non-null  object \n",
      " 7   Brand          100050 non-null  object \n",
      " 8   Quantity       100050 non-null  int64  \n",
      " 9   UnitPrice      95053 non-null   float64\n",
      " 10  Discount       97009 non-null   float64\n",
      " 11  Tax            100050 non-null  float64\n",
      " 12  ShippingCost   100050 non-null  object \n",
      " 13  TotalAmount    100050 non-null  object \n",
      " 14  PaymentMethod  100050 non-null  object \n",
      " 15  OrderStatus    100050 non-null  object \n",
      " 16  City           99070 non-null   object \n",
      " 17  State          100050 non-null  object \n",
      " 18  Country        100050 non-null  object \n",
      " 19  SellerID       100050 non-null  object \n",
      "dtypes: float64(3), int64(1), object(16)\n",
      "memory usage: 15.3+ MB\n",
      "\n",
      "--- PROCESO COMPLETADO ---\n"
     ]
    }
   ],
   "source": [
    "dirty_file_name = \"Amazon_DIRTY.csv\"\n",
    "df_dirty.to_csv(dirty_file_name, index=False, encoding='utf-8')\n",
    "\n",
    "print(\"\\n--- RESUMEN DEL DATASET SUCIO ---\")\n",
    "print(f\"¡Conjunto de datos sucio guardado como: {dirty_file_name}!\")\n",
    "print(\"\\nInformación de Tipos de Datos (Dtypes):\")\n",
    "df_dirty.info()\n",
    "print(\"\\n--- PROCESO COMPLETADO ---\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tareaensuciar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
