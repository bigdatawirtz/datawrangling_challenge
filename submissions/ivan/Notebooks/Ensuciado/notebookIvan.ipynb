{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b76cf979",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "datos = pd.read_csv(\"../Datasets/F1Drivers_Dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9033c4ac",
   "metadata": {},
   "source": [
    "## **Eliminación de datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b144a0",
   "metadata": {},
   "source": [
    "1. **Datos faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7c0dc0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilidad_nan = 0.05 \n",
    "mascara = np.random.choice([True, False], size=datos.shape, p=[probabilidad_nan, 1 - probabilidad_nan]) # Crear una matriz de decisiones que tiene la misma forma que nuestros datos, y esas decisiones son True o False.\n",
    "\n",
    "datos= datos.mask(mascara)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a041dc6",
   "metadata": {},
   "source": [
    "2. **Filas duplicadas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4ba0598f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_filas_a_duplicar = int(datos.shape[0] * 0.2)\n",
    "filas_duplicadas = datos.sample(n=num_filas_a_duplicar, replace=False) # Seleccionamos las filas que se duplicarán al azar\n",
    "datos = pd.concat([datos, filas_duplicadas], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c3acd",
   "metadata": {},
   "source": [
    "3. **Valores atípicos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f776d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_numericas = datos.select_dtypes(include=np.number).columns\n",
    "\n",
    "probability_of_outlier = 0.05\n",
    "\n",
    "MAGNITUD_EXTREMA = 100\n",
    "\n",
    "df_con_outliers = datos.copy()\n",
    "\n",
    "for col in columnas_numericas:\n",
    "    #Calcular la media de la columna (para referencia)\n",
    "    media = datos[col].mean()\n",
    "\n",
    "    # Genera True donde debe ir el outlier (5% de las veces)\n",
    "    mask = np.random.choice(\n",
    "        [True, False],\n",
    "        size=datos.shape[0], # El tamaño es el número de filas\n",
    "        p=[probability_of_outlier, 1 - probability_of_outlier]\n",
    "    )\n",
    "\n",
    "    #Determinar los valores atípicos a insertar\n",
    "    outlier_alto = media * MAGNITUD_EXTREMA\n",
    "    #Un valor extremo bajo (ej. -100 veces la media, si es aplicable)\n",
    "    outlier_bajo = media * (-MAGNITUD_EXTREMA)\n",
    "\n",
    "    # Decidir si será alto o bajo al azar (50/50)\n",
    "    valor_a_inyectar = np.random.choice([outlier_alto, outlier_bajo], size=datos.shape[0])\n",
    "\n",
    "\n",
    "    # Usamos .loc para inyectar los valores solo donde la máscara es True\n",
    "    # Inyectamos el valor aleatorio (alto o bajo) en las posiciones True\n",
    "    df_con_outliers.loc[mask, col] = valor_a_inyectar[mask]\n",
    "\n",
    "datos= df_con_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e07b5c4",
   "metadata": {},
   "source": [
    "4. **Inconsistencias de formato**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6066fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2978/636887584.py:12: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '2,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '-8,962739174219536' 'nan' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '2,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '-8,962739174219536' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' 'nan' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '1,0' '0,0' '0,0' '0,0' '0,0' '0,0' '1,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " 'nan' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '8,962739174219536' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '8,962739174219536' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '8,962739174219536' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '1,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '1,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '8,962739174219536'\n",
      " '0,0' '0,0' 'nan' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' 'nan' '0,0' '0,0' '0,0' '8,962739174219536' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '8,962739174219536' '3,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '0,0' '2,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '7,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '3,0' '0,0' '0,0' '0,0' '0,0' '-8,962739174219536'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' 'nan' '8,962739174219536'\n",
      " '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0' '0,0']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  datos.loc[mask_sep, COLUMNA_A_MODIFICAR] = \\\n"
     ]
    }
   ],
   "source": [
    "COLUMNA_A_MODIFICAR = 'Championships'\n",
    "PROBABILIDAD_MODIFICACION = 0.4  \n",
    "\n",
    "# Crear la máscara booleana\n",
    "mask_sep = np.random.choice(\n",
    "    [True, False],\n",
    "    size=datos.shape[0],\n",
    "    p=[PROBABILIDAD_MODIFICACION, 1 - PROBABILIDAD_MODIFICACION]\n",
    ")\n",
    "\n",
    "# Aplicar la conversión a string y cambiar el punto por la coma\n",
    "datos.loc[mask_sep, COLUMNA_A_MODIFICAR] = \\\n",
    "    datos.loc[mask_sep, COLUMNA_A_MODIFICAR].apply(\n",
    "        lambda x: str(x).replace('.', ',')\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83377c23",
   "metadata": {},
   "source": [
    "5. **Errores tipográficos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2b4433",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNA_DRIVER = 'Driver'\n",
    "\n",
    "# Lista de prefijos o sufijos que simulan errores de entrada, ortografía o etiquetas\n",
    "PREFIJOS_ERROR = [\"ERROR_\", \"FAIL_\", \"DATA_\", \"TYPO_\", \"WRONG_\", \"_MISSPELL\"]\n",
    "\n",
    "def inyectar_error_tipografico(palabra):\n",
    "    if pd.isna(palabra) or len(palabra) < 3:\n",
    "        return palabra\n",
    "\n",
    "    # Elegir una posición al azar para el error\n",
    "    idx = np.random.randint(0, len(palabra))\n",
    "\n",
    "    # Elegir un carácter al azar\n",
    "    nuevo_caracter = np.random.choice(list('abcdefghijklmnñopqrstuvwxyz'))\n",
    "\n",
    "    # Construir la palabra con el error\n",
    "    palabra_mutada = list(palabra)\n",
    "    palabra_mutada[idx] = nuevo_caracter\n",
    "    return \"\".join(palabra_mutada)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "PROBABILIDAD_ERROR = 0.2 \n",
    "\n",
    "mask_error = np.random.choice(\n",
    "    [True, False],\n",
    "    size=datos.shape[0],\n",
    "    p=[PROBABILIDAD_ERROR, 1 - PROBABILIDAD_ERROR]\n",
    ")\n",
    "\n",
    "\n",
    "datos.loc[mask_error, COLUMNA_DRIVER] = \\\n",
    "    datos.loc[mask_error, COLUMNA_DRIVER].apply(inyectar_error_tipografico)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98a8cbd1",
   "metadata": {},
   "source": [
    "6. **Categorías adicionales**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0127e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNAS_CATEGORICAS = ['Nationality', 'Championship Years', 'Decade', 'Active', 'Champion']\n",
    "\n",
    "CATEGORIAS_INUSUALES = [\n",
    "    \"UNKNOWN_VALUE\",\n",
    "    \"N/A_INPUT\",\n",
    "    \"INVALID_ENTRY\",\n",
    "    \"Z_OUTLIER\",\n",
    "    \"ERROR_CHECK\"\n",
    "]\n",
    "\n",
    "PROBABILIDAD_INYECCION = 0.05\n",
    "\n",
    "def inyectar_categoria_inusual(valor_original):\n",
    "    # Usamos np.random.choice para elegir una categoría de la lista\n",
    "    return np.random.choice(CATEGORIAS_INUSUALES)\n",
    "\n",
    "\n",
    "for columna in COLUMNAS_CATEGORICAS:\n",
    "    mask_adicional = np.random.choice(\n",
    "        [True, False],\n",
    "        size=datos.shape[0],\n",
    "        p=[PROBABILIDAD_INYECCION, 1 - PROBABILIDAD_INYECCION]\n",
    "    )\n",
    "\n",
    "   \n",
    "    datos.loc[mask_adicional, columna] = \\\n",
    "        datos.loc[mask_adicional, columna].apply(inyectar_categoria_inusual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3505c651",
   "metadata": {},
   "source": [
    "7. **Tipos de datos incorrectos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d22f907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La columna 'Race_Starts' ha sido convertida completamente a tipo string (object).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                   0.0\n",
       "1                   2.0\n",
       "2                   nan\n",
       "3                  30.0\n",
       "4    -2830.532786885246\n",
       "Name: Race_Starts, dtype: object"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COLUMNA_ACTIVA = 'Race_Starts'\n",
    "\n",
    "datos[COLUMNA_ACTIVA] = datos[COLUMNA_ACTIVA].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b6de19",
   "metadata": {},
   "source": [
    "9. **Encabezados incorrectos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a11be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_originales = datos.columns.tolist()\n",
    "\n",
    "\n",
    "mapeo_errores = {\n",
    "    \n",
    "    'Points': 'Puntos$$', \n",
    "    'Championships': 'cHaMpIoNsHiPs',\n",
    "}\n",
    "\n",
    "\n",
    "datos.rename(columns=mapeo_errores, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7d343",
   "metadata": {},
   "source": [
    "10. **Símbolos de puntuación extra (1000 € )**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "616cefe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2978/3839994602.py:33: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '['32.0€' '0.0$' '1.0€' '0.0€' '0.0€' '0.0$' '0.0€' '0.0$' '0.0€' '0.0€'\n",
      " '0.0€' '6.0$' '1.0€' '0.0€' '0.0$' '0.0€' '0.0$' '0.0€' '0.0€' '0.0€'\n",
      " '0.0$' '0.0€' '0.0€' nan '119.358074222668$' '0.0€' '0.0$'\n",
      " '-119.358074222668€' '119.358074222668$' '0.0€' '0.0€' '0.0€' '0.0€'\n",
      " '0.0$' '0.0€' '0.0€' '0.0€' '0.0$' '0.0€' '0.0€' '0.0$' '0.0€' nan '0.0€'\n",
      " '0.0$' '0.0$' '0.0$' '0.0$' '0.0€' '0.0$' '119.358074222668€' '0.0€'\n",
      " '0.0$' '0.0$' '0.0€' '0.0$' nan '0.0€' '0.0€' '-119.358074222668€' '0.0€'\n",
      " '119.358074222668$' '0.0$' '0.0$' '0.0$' '-119.358074222668€' '0.0$'\n",
      " '0.0$' '0.0€' '0.0€' '0.0€' nan '0.0€' '1.0€' '0.0€' '0.0$' '0.0€' '0.0$'\n",
      " '0.0€' '0.0€' '2.0$']' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df_con_simbolos.loc[mask_simbolos, COLUMNA_ACTIVA] = \\\n"
     ]
    }
   ],
   "source": [
    "COLUMNA_ACTIVA = 'Race_Wins'\n",
    "\n",
    "SIMBOLOS_EXTRA = [\"€\", \"$\"]\n",
    "\n",
    "PROBABILIDAD_INYECCION = 0.08  \n",
    "\n",
    "\n",
    "def inyectar_simbolos_extra(valor_original):\n",
    "    # Manejar NaN/valores nulos para que no falle la conversión a string\n",
    "    if pd.isna(valor_original):\n",
    "        return valor_original\n",
    "\n",
    "    # Convertir a string para poder manipular el texto\n",
    "    valor_str = str(valor_original)\n",
    "\n",
    "    # Elegir un símbolo al azar\n",
    "    simbolo = np.random.choice(SIMBOLOS_EXTRA)\n",
    "\n",
    "    return valor_str + simbolo\n",
    "\n",
    "\n",
    "# Asumiendo que tu DataFrame se llama 'datos'\n",
    "df_con_simbolos = datos.copy()\n",
    "\n",
    "    # 1. Crear la máscara booleana específica para la columna\n",
    "mask_simbolos = np.random.choice(\n",
    "    [True, False],\n",
    "    size=df_con_simbolos.shape[0],\n",
    "    p=[PROBABILIDAD_INYECCION, 1 - PROBABILIDAD_INYECCION]\n",
    ")\n",
    "\n",
    "    # 2. Aplicar la función de inyección solo a las filas seleccionadas (usando .loc)\n",
    "df_con_simbolos.loc[mask_simbolos, COLUMNA_ACTIVA] = \\\n",
    "    df_con_simbolos.loc[mask_simbolos, COLUMNA_ACTIVA].apply(inyectar_simbolos_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2870c468",
   "metadata": {},
   "source": [
    "8. **No hay codificación**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "303ffdf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "datos.to_csv('DatosSucios.csv', encoding='latin-1', index=False, errors='ignore')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bicis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
